{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dcgan_pytorch2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kylematoba/GAN-Metrics/blob/master/dcgan_pytorch2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTrMcMltRSQH",
        "colab_type": "code",
        "outputId": "e386caef-7598-40f7-dc1c-d05530d959e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install --upgrade setuptools"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: setuptools in /usr/local/lib/python3.6/dist-packages (41.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvH7qnpmTI5A",
        "colab_type": "code",
        "outputId": "adb4bfcd-34e9-4d1e-cfae-5dd9f7ad19aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# !rm -rf examples\n",
        "!git clone https://github.com/kylematoba/examples.git\n",
        "# !git -C examples log -n 2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'examples' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfsI5MSHQSJ3",
        "colab_type": "code",
        "outputId": "c05ca223-5637-4af4-f787-8ab6efb6f053",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# !rm -rf gan_metrics\n",
        "!git clone https://kylematoba:!!czsnd889.!!!!@github.com/kylematoba/GAN-Metrics.git gan_metrics"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'gan_metrics' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT5mwRBMOrt-",
        "colab_type": "code",
        "outputId": "75fd4e48-c17f-4ea7-bea8-f26e3bd91bdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "!pip3 install pot"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pot in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pot) (1.16.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from pot) (3.0.3)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from pot) (0.29.7)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from pot) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pot) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pot) (2.4.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pot) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pot) (2.5.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->pot) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->pot) (41.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdnOpHY1kl7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import sys\n",
        "import logging\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "import gan_metrics.metric as metric\n",
        "\n",
        "FORMAT = \"%(asctime)s %(process)s %(thread)s: %(message)s\"\n",
        "logging.basicConfig(level=logging.INFO, format=FORMAT, stream=sys.stdout)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "to_addrs = ['kylematoba@gmail.com']\n",
        "dict_environ = dict(os.environ)\n",
        "# logger.info(pprint.pformat(dict_environ, indent=4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p71Nrh9AxBkB",
        "colab_type": "code",
        "outputId": "8dbc1d05-5f94-44d9-89d8-7ccae074444f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "!rm -rf matobapythong\n",
        "!pip3 install --force-reinstall git+https://kylematoba:!!czsnd889.!!!!@github.com/kylematoba/matobapython.git"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://kylematoba:****@github.com/kylematoba/matobapython.git\n",
            "  Cloning https://kylematoba:****@github.com/kylematoba/matobapython.git to /tmp/pip-req-build-ztbgo50d\n",
            "  Running command git clone -q 'https://kylematoba:!!czsnd889.!!!!@github.com/kylematoba/matobapython.git' /tmp/pip-req-build-ztbgo50d\n",
            "Building wheels for collected packages: matobapython\n",
            "  Building wheel for matobapython (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-d9zx50jk/wheels/e1/2d/7a/3c81733c70f1f3d702f15d4d9f352f995deacb0ee96b476c47\n",
            "Successfully built matobapython\n",
            "Installing collected packages: matobapython\n",
            "  Found existing installation: matobapython 0.0.1\n",
            "    Uninstalling matobapython-0.0.1:\n",
            "      Successfully uninstalled matobapython-0.0.1\n",
            "Successfully installed matobapython-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w_lu9eoxF9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pythonutils.gdrive as gdrive\n",
        "import pythonutils.plotting as plotting\n",
        "import pythonutils.send_email as send_email"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhveQGed9tZV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metric_names = np.array(['pixl_wasserstein', 'pixl_mmd', 'pixl_acc', 'pixl_acc_t',\n",
        "                         'pixl_acc_f', 'pixl_precision', 'pixl_recall', 'conv_wasserstein',\n",
        "                         'conv_mmd', 'conv_acc', 'conv_acc_t', 'conv_acc_f',\n",
        "                         'conv_precision', 'conv_recall', 'logit_wasserstein', 'logit_mmd',\n",
        "                         'logit_acc', 'logit_acc_t', 'logit_acc_f', 'logit_precision',\n",
        "                         'logit_recall', 'smax_wasserstein', 'smax_mmd', 'smax_acc',\n",
        "                         'smax_acc_t', 'smax_acc_f', 'smax_precision', 'smax_recall',\n",
        "                         'inception_score', 'mode_score', 'fid'], dtype=object)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irLFxc4dkpKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataroot = 'examples'\n",
        "# prng_seed = None\n",
        "\n",
        "# seed_char = 'a'\n",
        "# seed_char = 'b'\n",
        "# seed_char = 'c'\n",
        "# seed_char = 'd'\n",
        "# seed_char = 'e'\n",
        "# seed_char = 'f'\n",
        "# seed_char = 'g'\n",
        "# seed_char = 'h'\n",
        "# seed_char = 'i'\n",
        "# seed_char = 'j'\n",
        "# seed_char = 'k'\n",
        "seed_char = 'l'\n",
        "# seed_char = 'm'\n",
        "\n",
        "prng_seed = ord(seed_char)\n",
        "\n",
        "# prng_seed = 8\n",
        "# prng_seed = 1\n",
        "# prng_seed = 10\n",
        "batch_size = 64\n",
        "image_size = 64\n",
        "is_cuda = True\n",
        "lr = 0.0002\n",
        "beta1 = .5\n",
        "\n",
        "# max_iter = 3\n",
        "# max_iter = 10\n",
        "max_iter = 25\n",
        "\n",
        "num_workers = 2\n",
        "ngpu = 1\n",
        "\n",
        "# nz = 1\n",
        "# nz = 2\n",
        "# nz = 5\n",
        "# nz = 10\n",
        "# nz = 25\n",
        "# nz = 50\n",
        "# nz = 95\n",
        "# nz = 100\n",
        "nz = 200\n",
        "\n",
        "ngf = 64\n",
        "ndf = 64\n",
        "if prng_seed is None:\n",
        "    prng_seed = random.randint(1, 10000)\n",
        "\n",
        "# assert prng_seed < 1000, \"Not supporting seeds with more than 5 digits\"\n",
        "# identifier = 'ident'\n",
        "# identifier_base = 'z{:05d}seed{:05d}'.format(nz, prng_seed)\n",
        "zstr = 'z{:05d}'.format(nz)\n",
        "seedstr = 'seed_{}'.format(seed_char)\n",
        "\n",
        "out_folder_local = '/content'\n",
        "\n",
        "# dataset_name = 'lsun'\n",
        "# dataset_name = 'mnist'\n",
        "dataset_name = 'cifar10'\n",
        "\n",
        "identifier = dataset_name + zstr + seedstr\n",
        "\n",
        "print_every_iteration = 200\n",
        "save_every_iteration = 200\n",
        "# checkpoint_every_epoch = 2\n",
        "checkpoint_every_epoch = 4\n",
        "\n",
        "# logger.info(\"Identifier: {}\".format(identifier))\n",
        "metrics_pattern = \"metrics_{:04d}.npy\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cxciv29hTna5",
        "colab_type": "code",
        "outputId": "268eeba4-1b48-4f73-e96e-46ef16a22d53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "logger.info(\"Random Seed: {}\".format(prng_seed))\n",
        "random.seed(prng_seed)\n",
        "torch.manual_seed(prng_seed)\n",
        "\n",
        "cudnn.benchmark = True\n",
        "\n",
        "if torch.cuda.is_available() and not is_cuda:\n",
        "    logger.info(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
        "    \n",
        "if dataset_name in ['imagenet', 'folder', 'lfw']:\n",
        "    dataset = dset.ImageFolder(root=dataroot,\n",
        "                               transform=transforms.Compose([\n",
        "                                   transforms.Resize(image_size),\n",
        "                                   transforms.CenterCrop(image_size),\n",
        "                                   transforms.ToTensor(),\n",
        "                                   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                               ]))\n",
        "    nc=3\n",
        "elif dataset_name == 'lsun':\n",
        "    dataset = dset.LSUN(root=dataroot, classes=['bedroom_train'],\n",
        "                        transform=transforms.Compose([\n",
        "                            transforms.Resize(image_size),\n",
        "                            transforms.CenterCrop(image_size),\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                        ]))\n",
        "    nc=3\n",
        "elif dataset_name == 'cifar10':\n",
        "    dataset = dset.CIFAR10(root=dataroot, download=True,\n",
        "                           transform=transforms.Compose([\n",
        "                               transforms.Resize(image_size),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                           ]))\n",
        "    nc=3\n",
        "elif dataset_name == 'mnist':\n",
        "        dataset = dset.MNIST(root=dataroot, download=True,\n",
        "                           transform=transforms.Compose([\n",
        "                               transforms.Resize(image_size),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.5,), (0.5,)),\n",
        "                           ]))\n",
        "        nc=1\n",
        "elif dataset_name == 'fake':\n",
        "    dataset = dset.FakeData(image_size=(3, image_size, image_size),\n",
        "                            transform=transforms.ToTensor())\n",
        "    nc=3\n",
        "\n",
        "assert dataset\n",
        "device = torch.device(\"cuda:0\" if is_cuda else \"cpu\")\n",
        "\n",
        "\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngpu: int):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(     nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        if input.is_cuda and self.ngpu > 1:\n",
        "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
        "        else:\n",
        "            output = self.main(input)\n",
        "        return output\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu: int):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        if input.is_cuda and self.ngpu > 1:\n",
        "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
        "        else:\n",
        "            output = self.main(input)\n",
        "        return output.view(-1, 1).squeeze(1)\n",
        "\n",
        "netG = Generator(ngpu).to(device)\n",
        "netG.apply(weights_init)\n",
        "\n",
        "netD = Discriminator(ngpu).to(device)\n",
        "netD.apply(weights_init)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-05-04 19:27:53,983 861 140249963870080: Random Seed: 108\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (main): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
              "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): LeakyReLU(negative_slope=0.2, inplace)\n",
              "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): LeakyReLU(negative_slope=0.2, inplace)\n",
              "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (10): LeakyReLU(negative_slope=0.2, inplace)\n",
              "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
              "    (12): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zx1BHJhM6qK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _delete_all_remote_files(del_filename: str, \n",
        "                             parent_fid: str) -> None:\n",
        "    del_files = gdrive.find_items(name=del_filename, \n",
        "                                  parent_fid=parent_fid, \n",
        "                                  skip_trashed=True)\n",
        "    for x in del_files:\n",
        "        logger.info(\"Deleting {}\".format(x))\n",
        "        delete_fid = x[1]\n",
        "        gdrive.delete_file(delete_fid)\n",
        "        \n",
        "        \n",
        "def _create_folder_in_parent(folder_name: str, \n",
        "                             parent_fid: str, \n",
        "                             exist_ok: bool) -> str:\n",
        "    found_folders = gdrive.find_items(folder_name, \n",
        "                                      parent_fid, \n",
        "                                      skip_trashed=True)\n",
        "    num_found = len(found_folders)\n",
        "    assert num_found <= 1, \"Multiple matches, refine query\"\n",
        "\n",
        "    if 1 == num_found:\n",
        "        found_folder = found_folders[0] \n",
        "        folder_fid = found_folder[1]\n",
        "        logger.info(\"Found it, {}\".format(folder_fid))\n",
        "        assert exist_ok, \"Not expecting to find it\"\n",
        "    else:\n",
        "        created_folder = gdrive.create_folder(folder_name=folder_name, \n",
        "                                              parent_fid=parent_fid)\n",
        "        folder_fid = created_folder[1]\n",
        "        logger.info(\"Not found, created with fid = {}\".format(folder_fid))\n",
        "    return folder_fid\n",
        "\n",
        "  \n",
        "def _get_epoch_from_checkpoint(x: str) -> int:\n",
        "    return int(x.rstrip('.pth').split('epoch')[-1])\n",
        "  \n",
        "  \n",
        "def _download_file_locally(filename: str, \n",
        "                           parent_fid: str) -> None:\n",
        "    remote_files = gdrive.find_items(filename, \n",
        "                                     parent_fid, \n",
        "                                     skip_trashed=True)\n",
        "    assert 1 == len(remote_files), str(remote_files)\n",
        "    remote_file = remote_files[0]\n",
        "    remote_fid = remote_file[1]\n",
        "    gdrive.download_file_to_folder(remote_fid, filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6r8HTg7ULvRj",
        "colab_type": "code",
        "outputId": "e8c7377b-a81c-4efd-adaf-f65199cd40f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 871
        }
      },
      "source": [
        "# Check whether there are checkpoints in the google drive\n",
        "username = 'robotmatoba'\n",
        "gdrive.authenticate_automatically(username)\n",
        "\n",
        "base_folder_name = 'PytorchCheckpoints'\n",
        "\n",
        "logger.info(\"Setting up base folder '{}'\".format(base_folder_name))\n",
        "base_folder_fid = _create_folder_in_parent(folder_name=base_folder_name, parent_fid=None, exist_ok=True)\n",
        "\n",
        "logger.info(\"Setting up dataset folder '{}' in '{}'\".format(dataset_name, base_folder_name))\n",
        "dataset_folder_fid = _create_folder_in_parent(folder_name=dataset_name, parent_fid=base_folder_fid, exist_ok=True)\n",
        "\n",
        "logger.info(\"Setting up dataset/z/ folder '{}' in '{}'\".format(zstr, dataset_name))\n",
        "datasetz_folder_fid = _create_folder_in_parent(folder_name=zstr, parent_fid=dataset_folder_fid, exist_ok=True)\n",
        "\n",
        "logger.info(\"Setting up dataset/z/seed folder '{}' in '{}'\".format(seedstr, zstr))\n",
        "datasetzseed_folder_fid = _create_folder_in_parent(folder_name=seedstr, parent_fid=datasetz_folder_fid, exist_ok=True)\n",
        "\n",
        "# logger.info(\"Creating experiment subfolder '{}' with parent fid '{}'\".format(dataset_name, base_fid))\n",
        "# dataset_folder = gdrive.create_folder(dataset_name, [base_fid.fid])\n",
        "# # identifier_folder = gdrive.create_folder(dataset_name, [base_fid.fid])\n",
        "# # Folder structure is:\n",
        "# # dataset/nz/\n",
        "\n",
        "parent_fid = datasetzseed_folder_fid"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-05-04 19:27:58,922 861 140249963870080: Setting up base folder 'PytorchCheckpoints'\n",
            "2019-05-04 19:27:58,923 861 140249963870080: Submitting query 'name contains \"PytorchCheckpoints\" and trashed = false'\n",
            "2019-05-04 19:27:58,930 861 140249963870080: file_cache is unavailable when using oauth2client >= 4.0.0\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 36, in autodetect\n",
            "    from google.appengine.api import memcache\n",
            "ModuleNotFoundError: No module named 'google.appengine'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 41, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    'file_cache is unavailable when using oauth2client >= 4.0.0')\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0\n",
            "2019-05-04 19:27:58,931 861 140249963870080: URL being requested: GET https://www.googleapis.com/discovery/v1/apis/drive/v3/rest\n",
            "2019-05-04 19:27:58,982 861 140249963870080: No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n",
            "2019-05-04 19:27:58,988 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22PytorchCheckpoints%22+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:27:59,222 861 140249963870080: Found it, 1t4s77dg0G5hm0TlHvnrQkBYpJ64wuHml\n",
            "2019-05-04 19:27:59,223 861 140249963870080: Setting up dataset folder 'cifar10' in 'PytorchCheckpoints'\n",
            "2019-05-04 19:27:59,224 861 140249963870080: Submitting query 'name contains \"cifar10\" and \"1t4s77dg0G5hm0TlHvnrQkBYpJ64wuHml\" in parents and trashed = false'\n",
            "2019-05-04 19:27:59,231 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22cifar10%22+and+%221t4s77dg0G5hm0TlHvnrQkBYpJ64wuHml%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:27:59,418 861 140249963870080: Found it, 1_3XHVYiPP8uoSvr-J5SYE97or8rgCecF\n",
            "2019-05-04 19:27:59,419 861 140249963870080: Setting up dataset/z/ folder 'z00200' in 'cifar10'\n",
            "2019-05-04 19:27:59,420 861 140249963870080: Submitting query 'name contains \"z00200\" and \"1_3XHVYiPP8uoSvr-J5SYE97or8rgCecF\" in parents and trashed = false'\n",
            "2019-05-04 19:27:59,427 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22z00200%22+and+%221_3XHVYiPP8uoSvr-J5SYE97or8rgCecF%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:27:59,601 861 140249963870080: URL being requested: POST https://www.googleapis.com/drive/v3/files?fields=id&alt=json\n",
            "2019-05-04 19:28:00,079 861 140249963870080: Not found, created with fid = 1PLWPw269gdWFzZSKEob_VWiasxnQoBgW\n",
            "2019-05-04 19:28:00,080 861 140249963870080: Setting up dataset/z/seed folder 'seed_l' in 'z00200'\n",
            "2019-05-04 19:28:00,081 861 140249963870080: Submitting query 'name contains \"seed_l\" and \"1PLWPw269gdWFzZSKEob_VWiasxnQoBgW\" in parents and trashed = false'\n",
            "2019-05-04 19:28:00,090 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22seed_l%22+and+%221PLWPw269gdWFzZSKEob_VWiasxnQoBgW%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:00,262 861 140249963870080: URL being requested: POST https://www.googleapis.com/drive/v3/files?fields=id&alt=json\n",
            "2019-05-04 19:28:00,783 861 140249963870080: Not found, created with fid = 1mxzCSp8zzJaAO0m66V7V3vbg2BrAcRxJ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLwao4Oh727P",
        "colab_type": "code",
        "outputId": "f5cd96f1-3be4-46a1-9f68-35b3cb12579b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "collate_epoch = 24\n",
        "\n",
        "filename = metrics_pattern.format(collate_epoch)\n",
        "\n",
        "idents_tuples = gdrive.list_dir(dataset_folder_fid)\n",
        "\n",
        "num_idents = len(idents_tuples)\n",
        "load_metrics = ['conv_wasserstein', 'conv_mmd', 'conv_acc', 'conv_acc_t', \n",
        "                'conv_acc_f', 'conv_precision', 'conv_recall', \n",
        "                'inception_score', 'mode_score', 'fid']\n",
        "\n",
        "\n",
        "metrics = {k[0]: None for k in idents_tuples}\n",
        "num_metrics = len(load_metrics)\n",
        "\n",
        "# print(metrics)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-05-04 19:28:00,800 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=%221_3XHVYiPP8uoSvr-J5SYE97or8rgCecF%22+in+parents&alt=json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mcn-4zE628pO",
        "colab_type": "code",
        "outputId": "e95ca8c2-27ba-4c62-b6be-762ea9d9da31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3476
        }
      },
      "source": [
        "for idx, ident_tuple in enumerate(idents_tuples):  # idx = 1; ident_tuple = idents_tuples[1]\n",
        "    ident = ident_tuple[0]\n",
        "    ident_fid = ident_tuple[1]\n",
        "    logger.info(\"Loading from {}\".format(ident))\n",
        "    \n",
        "    metrics_pattern.format(collate_epoch)\n",
        "    \n",
        "    seed_tuples = gdrive.list_dir(ident_fid)\n",
        "    num_seeds = len(seed_tuples)\n",
        "    logger.info(\"Found {} seeds\".format(num_seeds))\n",
        "  \n",
        "    to_assign_np = np.full((num_seeds, num_metrics), np.nan)\n",
        "    seed_index = [None] * num_seeds  # np.full((num_seeds, ), np.nan)\n",
        "    for seed_idx, seed_tuple in enumerate(seed_tuples):\n",
        "        seed_identifier = seed_tuple[0]\n",
        "        seed_fid = seed_tuple[1]\n",
        "        seed_index[seed_idx] = seed_identifier\n",
        "        # logger.info(\"Downloading {}/{} to {}\".format(ident, seed_identifier))\n",
        "        metrics_filename = metrics_pattern.format(collate_epoch)\n",
        "        \n",
        "        try:\n",
        "            _download_file_locally(metrics_filename, seed_fid)\n",
        "            logger.info(\"Loading {} from {}\".format(metrics_filename, seed_fid))\n",
        "            s = np.load(metrics_filename)\n",
        "        except Exception as e:\n",
        "            s = None\n",
        "        s_pd = pd.Series(s, index=metric_names)\n",
        "        loaded_metrics = s_pd[load_metrics]\n",
        "        to_assign_np[seed_idx, :] = loaded_metrics.copy()\n",
        "\n",
        "    to_assign = pd.DataFrame(to_assign_np, \n",
        "                             index=seed_index, \n",
        "                             columns=load_metrics).sort_index(axis=0)      \n",
        "    metrics[ident] = to_assign"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-05-04 19:28:01,015 861 140249963870080: Loading from z00200\n",
            "2019-05-04 19:28:01,021 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=%221PLWPw269gdWFzZSKEob_VWiasxnQoBgW%22+in+parents&alt=json\n",
            "2019-05-04 19:28:01,222 861 140249963870080: Found 1 seeds\n",
            "2019-05-04 19:28:01,224 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1mxzCSp8zzJaAO0m66V7V3vbg2BrAcRxJ\" in parents and trashed = false'\n",
            "2019-05-04 19:28:01,231 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221mxzCSp8zzJaAO0m66V7V3vbg2BrAcRxJ%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:01,412 861 140249963870080: Loading from z00005\n",
            "2019-05-04 19:28:01,419 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=%221e_vxr1tMfMOD44wgSuzbPDkvSGNDwL8X%22+in+parents&alt=json\n",
            "2019-05-04 19:28:01,613 861 140249963870080: Found 13 seeds\n",
            "2019-05-04 19:28:01,615 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1ioPKu-ixd9STv4qDYc8uFC1x-5CVD0h8\" in parents and trashed = false'\n",
            "2019-05-04 19:28:01,620 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221ioPKu-ixd9STv4qDYc8uFC1x-5CVD0h8%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:01,795 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/1gtMYlHF8CQC8EVIEEp6WHEhXxUXWZwau?alt=media\n",
            "2019-05-04 19:28:02,045 861 140249963870080: Loading metrics_0024.npy from 1ioPKu-ixd9STv4qDYc8uFC1x-5CVD0h8\n",
            "2019-05-04 19:28:02,049 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1urcRUt0tiYVrscKEWTKpHii19tIbYUr4\" in parents and trashed = false'\n",
            "2019-05-04 19:28:02,054 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221urcRUt0tiYVrscKEWTKpHii19tIbYUr4%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:02,242 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/1p4IKR1eT8-S_qk08O-cyMksgUqKXzyV-?alt=media\n",
            "2019-05-04 19:28:02,485 861 140249963870080: Loading metrics_0024.npy from 1urcRUt0tiYVrscKEWTKpHii19tIbYUr4\n",
            "2019-05-04 19:28:02,489 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1Tt0O2v4MXgXTQYcPtTxRTqN9Zh3hdZII\" in parents and trashed = false'\n",
            "2019-05-04 19:28:02,495 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221Tt0O2v4MXgXTQYcPtTxRTqN9Zh3hdZII%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:02,664 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/1S7wrg0EIvgGfm8PhzWXV_7rKyQ8Lh9Dh?alt=media\n",
            "2019-05-04 19:28:02,947 861 140249963870080: Loading metrics_0024.npy from 1Tt0O2v4MXgXTQYcPtTxRTqN9Zh3hdZII\n",
            "2019-05-04 19:28:02,951 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1lXubZL9XNrCOdlHZCMfRw0bOeL9YSTDC\" in parents and trashed = false'\n",
            "2019-05-04 19:28:02,959 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221lXubZL9XNrCOdlHZCMfRw0bOeL9YSTDC%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:03,177 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1M4UMDcVZFu2o9awajRus7CAgsd6wvBzR\" in parents and trashed = false'\n",
            "2019-05-04 19:28:03,182 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221M4UMDcVZFu2o9awajRus7CAgsd6wvBzR%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:03,501 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/1Mz3QXd5BQbQ90sRh5fD3T4gcPkNP0bTL?alt=media\n",
            "2019-05-04 19:28:03,753 861 140249963870080: Loading metrics_0024.npy from 1M4UMDcVZFu2o9awajRus7CAgsd6wvBzR\n",
            "2019-05-04 19:28:03,756 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1E5fH9zLAaUjsNlGJ_Mx2Mzy55xHr6RTe\" in parents and trashed = false'\n",
            "2019-05-04 19:28:03,765 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221E5fH9zLAaUjsNlGJ_Mx2Mzy55xHr6RTe%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:03,943 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/1QNPvFVpc56mSljslE-RALUTRGhPCUuaM?alt=media\n",
            "2019-05-04 19:28:04,190 861 140249963870080: Loading metrics_0024.npy from 1E5fH9zLAaUjsNlGJ_Mx2Mzy55xHr6RTe\n",
            "2019-05-04 19:28:04,194 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1rmABbZefL0Y3PEGkmI9A4Taq6ANCku68\" in parents and trashed = false'\n",
            "2019-05-04 19:28:04,199 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221rmABbZefL0Y3PEGkmI9A4Taq6ANCku68%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:04,393 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/1KO6q18pJQIzpp1__AwAKo96q-lQFt1im?alt=media\n",
            "2019-05-04 19:28:04,665 861 140249963870080: Loading metrics_0024.npy from 1rmABbZefL0Y3PEGkmI9A4Taq6ANCku68\n",
            "2019-05-04 19:28:04,668 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1zqrfk5Afj4VVCHyQA09YIbWr7B9WHo0V\" in parents and trashed = false'\n",
            "2019-05-04 19:28:04,674 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221zqrfk5Afj4VVCHyQA09YIbWr7B9WHo0V%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:04,877 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/1yX9rc0O2sGm0H6ZrwahUrHmDN011vhMq?alt=media\n",
            "2019-05-04 19:28:05,216 861 140249963870080: Loading metrics_0024.npy from 1zqrfk5Afj4VVCHyQA09YIbWr7B9WHo0V\n",
            "2019-05-04 19:28:05,220 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1ak_3pcvxEPJS-f4ssM3D3-AJ31xuJswk\" in parents and trashed = false'\n",
            "2019-05-04 19:28:05,225 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221ak_3pcvxEPJS-f4ssM3D3-AJ31xuJswk%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:05,418 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/18sXxi5VENiCnzhzWjYLqGJMthEChZZlj?alt=media\n",
            "2019-05-04 19:28:05,652 861 140249963870080: Loading metrics_0024.npy from 1ak_3pcvxEPJS-f4ssM3D3-AJ31xuJswk\n",
            "2019-05-04 19:28:05,657 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1_YhDKosN3DpulIMltoLZvz6zlC8fFaJb\" in parents and trashed = false'\n",
            "2019-05-04 19:28:05,661 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221_YhDKosN3DpulIMltoLZvz6zlC8fFaJb%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:05,841 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/1emiMg75qRKbk5V0lt_R6YjJOQMO508hX?alt=media\n",
            "2019-05-04 19:28:06,300 861 140249963870080: Loading metrics_0024.npy from 1_YhDKosN3DpulIMltoLZvz6zlC8fFaJb\n",
            "2019-05-04 19:28:06,306 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1mxnoB-WbVFp5oKv61WVE0AOnNqP9LXcc\" in parents and trashed = false'\n",
            "2019-05-04 19:28:06,312 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221mxnoB-WbVFp5oKv61WVE0AOnNqP9LXcc%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:06,495 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/1xGPncZJjn4FGKIYOgss_N9-SHiwpxFYL?alt=media\n",
            "2019-05-04 19:28:06,861 861 140249963870080: Loading metrics_0024.npy from 1mxnoB-WbVFp5oKv61WVE0AOnNqP9LXcc\n",
            "2019-05-04 19:28:06,867 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1c6Bqp2Xnkg20mnRJWPTMU6OKTSQJrqts\" in parents and trashed = false'\n",
            "2019-05-04 19:28:06,871 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221c6Bqp2Xnkg20mnRJWPTMU6OKTSQJrqts%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:07,069 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/1FiTw30rziY2JLDNUY4IgQa2ha4b24Dvb?alt=media\n",
            "2019-05-04 19:28:07,359 861 140249963870080: Loading metrics_0024.npy from 1c6Bqp2Xnkg20mnRJWPTMU6OKTSQJrqts\n",
            "2019-05-04 19:28:07,363 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"12Nt7eXbF5mhU7msvGj-cXlzV-kEE-i7H\" in parents and trashed = false'\n",
            "2019-05-04 19:28:07,370 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%2212Nt7eXbF5mhU7msvGj-cXlzV-kEE-i7H%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:07,576 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/1LRsIfGsWqBYJ6KxSbp3KplGWeqA7mnk4?alt=media\n",
            "2019-05-04 19:28:07,852 861 140249963870080: Loading metrics_0024.npy from 12Nt7eXbF5mhU7msvGj-cXlzV-kEE-i7H\n",
            "2019-05-04 19:28:07,856 861 140249963870080: Loading from z00010\n",
            "2019-05-04 19:28:07,864 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=%221Pp8ciR5uIINAuChE_YBwRKIZssDoQk4Y%22+in+parents&alt=json\n",
            "2019-05-04 19:28:08,052 861 140249963870080: Found 13 seeds\n",
            "2019-05-04 19:28:08,054 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1sVLCzM8pgj2x4Y7kiI9J7CnGZwQ9vGRM\" in parents and trashed = false'\n",
            "2019-05-04 19:28:08,060 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221sVLCzM8pgj2x4Y7kiI9J7CnGZwQ9vGRM%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:08,276 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/16YPtL11BBqYnxch52apsg-2xn6jhQo3g?alt=media\n",
            "2019-05-04 19:28:08,532 861 140249963870080: Loading metrics_0024.npy from 1sVLCzM8pgj2x4Y7kiI9J7CnGZwQ9vGRM\n",
            "2019-05-04 19:28:08,536 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1GyD_z1eknQu2yJNoMaVUFiUq_nrV26-m\" in parents and trashed = false'\n",
            "2019-05-04 19:28:08,541 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221GyD_z1eknQu2yJNoMaVUFiUq_nrV26-m%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:08,773 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/1dq-7hIRwdFHspMHRgNkxhKJu84zWfZv7?alt=media\n",
            "2019-05-04 19:28:09,161 861 140249963870080: Loading metrics_0024.npy from 1GyD_z1eknQu2yJNoMaVUFiUq_nrV26-m\n",
            "2019-05-04 19:28:09,164 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1Siuxy4DkPSZvyhLs4PUBQMlD7d4Gx9M3\" in parents and trashed = false'\n",
            "2019-05-04 19:28:09,170 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221Siuxy4DkPSZvyhLs4PUBQMlD7d4Gx9M3%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:09,356 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/1MOibbP0vnf5cGoVXLB-7VDAeNIYrZfAg?alt=media\n",
            "2019-05-04 19:28:09,880 861 140249963870080: Loading metrics_0024.npy from 1Siuxy4DkPSZvyhLs4PUBQMlD7d4Gx9M3\n",
            "2019-05-04 19:28:09,887 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1TWZdmwEWlN3xlTyy2w6cC4PzFRcXYSXR\" in parents and trashed = false'\n",
            "2019-05-04 19:28:09,891 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221TWZdmwEWlN3xlTyy2w6cC4PzFRcXYSXR%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:10,089 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/1EP6KohoGK80HrkV6WkhTuzzYU00PCc61?alt=media\n",
            "2019-05-04 19:28:10,452 861 140249963870080: Loading metrics_0024.npy from 1TWZdmwEWlN3xlTyy2w6cC4PzFRcXYSXR\n",
            "2019-05-04 19:28:10,455 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1HKwkeJ_bPpwJIs2RBBtwOyRf1fZq21dY\" in parents and trashed = false'\n",
            "2019-05-04 19:28:10,460 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221HKwkeJ_bPpwJIs2RBBtwOyRf1fZq21dY%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:10,657 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/1UePKEqXz3E2y67swocKl8AZAWreKjE5U?alt=media\n",
            "2019-05-04 19:28:10,904 861 140249963870080: Loading metrics_0024.npy from 1HKwkeJ_bPpwJIs2RBBtwOyRf1fZq21dY\n",
            "2019-05-04 19:28:10,909 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1FQOaDpILVEzPWbHWNx4DzOyr49sCpDpW\" in parents and trashed = false'\n",
            "2019-05-04 19:28:10,912 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221FQOaDpILVEzPWbHWNx4DzOyr49sCpDpW%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:11,130 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/156xi0C6HJscptKyiba2B892gmv9ywQDs?alt=media\n",
            "2019-05-04 19:28:11,417 861 140249963870080: Loading metrics_0024.npy from 1FQOaDpILVEzPWbHWNx4DzOyr49sCpDpW\n",
            "2019-05-04 19:28:11,423 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1zAb8-PYwJGFkQVKk-KXrf6Ckr67uW4Zg\" in parents and trashed = false'\n",
            "2019-05-04 19:28:11,427 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221zAb8-PYwJGFkQVKk-KXrf6Ckr67uW4Zg%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:11,655 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/1tM7EUTgtMIyLltzsHzg_VE5XH1c54ImP?alt=media\n",
            "2019-05-04 19:28:11,922 861 140249963870080: Loading metrics_0024.npy from 1zAb8-PYwJGFkQVKk-KXrf6Ckr67uW4Zg\n",
            "2019-05-04 19:28:11,929 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1sDtM9skjEdosesW2RCwB47G4gbadxw5J\" in parents and trashed = false'\n",
            "2019-05-04 19:28:11,932 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221sDtM9skjEdosesW2RCwB47G4gbadxw5J%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:12,279 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/1jYBS4VxfIAQJ5WTNbMPdptrR-d1cCDqU?alt=media\n",
            "2019-05-04 19:28:12,603 861 140249963870080: Loading metrics_0024.npy from 1sDtM9skjEdosesW2RCwB47G4gbadxw5J\n",
            "2019-05-04 19:28:12,608 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1Gk-qwbCCA7RsF-f3WKIbWc_uFlF3HOo-\" in parents and trashed = false'\n",
            "2019-05-04 19:28:12,613 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221Gk-qwbCCA7RsF-f3WKIbWc_uFlF3HOo-%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:12,878 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/1MGgjzmIaC4bH0NG3HTUYvuJRAHpjTY_y?alt=media\n",
            "2019-05-04 19:28:13,140 861 140249963870080: Loading metrics_0024.npy from 1Gk-qwbCCA7RsF-f3WKIbWc_uFlF3HOo-\n",
            "2019-05-04 19:28:13,145 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1-ZIlIzFMeQ7cPcoA7jger5iRBN_CL4Fg\" in parents and trashed = false'\n",
            "2019-05-04 19:28:13,152 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221-ZIlIzFMeQ7cPcoA7jger5iRBN_CL4Fg%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:13,365 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/1sNV0dxY2xtNlBWWQ5MGwTiOYz-uMNZ0L?alt=media\n",
            "2019-05-04 19:28:13,639 861 140249963870080: Loading metrics_0024.npy from 1-ZIlIzFMeQ7cPcoA7jger5iRBN_CL4Fg\n",
            "2019-05-04 19:28:13,645 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"11v1vZTg-ZpaiTkL1nqpFgl1J33BbJxsN\" in parents and trashed = false'\n",
            "2019-05-04 19:28:13,649 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%2211v1vZTg-ZpaiTkL1nqpFgl1J33BbJxsN%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:13,875 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/125u6CoIhzdp3ngAIltYoCS_4rP_YO8B8?alt=media\n",
            "2019-05-04 19:28:14,162 861 140249963870080: Loading metrics_0024.npy from 11v1vZTg-ZpaiTkL1nqpFgl1J33BbJxsN\n",
            "2019-05-04 19:28:14,169 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1k9t6BicFdaQHHGXTclR3a6P1oAtaZaxe\" in parents and trashed = false'\n",
            "2019-05-04 19:28:14,173 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221k9t6BicFdaQHHGXTclR3a6P1oAtaZaxe%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:14,363 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/1nQa3_zOn6MLIvr14MsjNFU0gVakIjTk1?alt=media\n",
            "2019-05-04 19:28:14,621 861 140249963870080: Loading metrics_0024.npy from 1k9t6BicFdaQHHGXTclR3a6P1oAtaZaxe\n",
            "2019-05-04 19:28:14,626 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1FnLL1MKxESVzggpXckNXTQDB6ORirCcs\" in parents and trashed = false'\n",
            "2019-05-04 19:28:14,632 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221FnLL1MKxESVzggpXckNXTQDB6ORirCcs%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:14,801 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/1KZiNXzWGd1Y-I0nefbT_-hMlcG-0bAua?alt=media\n",
            "2019-05-04 19:28:15,048 861 140249963870080: Loading metrics_0024.npy from 1FnLL1MKxESVzggpXckNXTQDB6ORirCcs\n",
            "2019-05-04 19:28:15,055 861 140249963870080: Loading from z00025\n",
            "2019-05-04 19:28:15,061 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=%221Ts4MMw6LiCaFfy4JfzW4WUk9wSeht14z%22+in+parents&alt=json\n",
            "2019-05-04 19:28:15,282 861 140249963870080: Found 11 seeds\n",
            "2019-05-04 19:28:15,283 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1YKQtoV71VO-NPYFfvlVZyq5h05N8OKA0\" in parents and trashed = false'\n",
            "2019-05-04 19:28:15,289 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221YKQtoV71VO-NPYFfvlVZyq5h05N8OKA0%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:15,470 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/1fy83UWrDV4ntUNxKY3vn9Qs6jdkh98gg?alt=media\n",
            "2019-05-04 19:28:15,799 861 140249963870080: Loading metrics_0024.npy from 1YKQtoV71VO-NPYFfvlVZyq5h05N8OKA0\n",
            "2019-05-04 19:28:15,804 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1m-XNNdI3lBaj1lEUDNsPBneGjkRIZwsz\" in parents and trashed = false'\n",
            "2019-05-04 19:28:15,809 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221m-XNNdI3lBaj1lEUDNsPBneGjkRIZwsz%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:16,054 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/1MgDGlOXQaKGhP8TSz2o93RNYAVIfVhEX?alt=media\n",
            "2019-05-04 19:28:16,308 861 140249963870080: Loading metrics_0024.npy from 1m-XNNdI3lBaj1lEUDNsPBneGjkRIZwsz\n",
            "2019-05-04 19:28:16,314 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1fTMSZlgohx3ucRFmLBMi74ImdNX49aL5\" in parents and trashed = false'\n",
            "2019-05-04 19:28:16,319 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221fTMSZlgohx3ucRFmLBMi74ImdNX49aL5%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:16,544 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/13lAapudviBvj2w1zWipvOuXg_quM1JlU?alt=media\n",
            "2019-05-04 19:28:16,817 861 140249963870080: Loading metrics_0024.npy from 1fTMSZlgohx3ucRFmLBMi74ImdNX49aL5\n",
            "2019-05-04 19:28:16,822 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1wH77imxk8BQ5dRIyvrfczEyPDpvGWBp8\" in parents and trashed = false'\n",
            "2019-05-04 19:28:16,829 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221wH77imxk8BQ5dRIyvrfczEyPDpvGWBp8%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:16,994 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/1YpxSviYX4NUkm0YcGaH31efucVv_Bkf4?alt=media\n",
            "2019-05-04 19:28:17,275 861 140249963870080: Loading metrics_0024.npy from 1wH77imxk8BQ5dRIyvrfczEyPDpvGWBp8\n",
            "2019-05-04 19:28:17,281 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"18g0Y1WXZppfO6qxkX86fNQFGogK6vH6t\" in parents and trashed = false'\n",
            "2019-05-04 19:28:17,284 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%2218g0Y1WXZppfO6qxkX86fNQFGogK6vH6t%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:17,464 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/1pLm_dBosEfkS-pbcTX5b2iKq0rB4os39?alt=media\n",
            "2019-05-04 19:28:17,884 861 140249963870080: Loading metrics_0024.npy from 18g0Y1WXZppfO6qxkX86fNQFGogK6vH6t\n",
            "2019-05-04 19:28:17,889 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"10QZnlQlJmbpqLljsiBKFr7LMoTdTgzLH\" in parents and trashed = false'\n",
            "2019-05-04 19:28:17,894 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%2210QZnlQlJmbpqLljsiBKFr7LMoTdTgzLH%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:18,092 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/1nZph2FwphjKlw42qlqEU6bRghjc34JFc?alt=media\n",
            "2019-05-04 19:28:18,421 861 140249963870080: Loading metrics_0024.npy from 10QZnlQlJmbpqLljsiBKFr7LMoTdTgzLH\n",
            "2019-05-04 19:28:18,427 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"191oAf4skT-pQIS3BlSZb5Ww9eGZ9mLLU\" in parents and trashed = false'\n",
            "2019-05-04 19:28:18,430 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%22191oAf4skT-pQIS3BlSZb5Ww9eGZ9mLLU%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:18,620 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/1Z4MyMxCTljnVaRA2U8ESewiGrAbeokGQ?alt=media\n",
            "2019-05-04 19:28:18,855 861 140249963870080: Loading metrics_0024.npy from 191oAf4skT-pQIS3BlSZb5Ww9eGZ9mLLU\n",
            "2019-05-04 19:28:18,861 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1Mgv419noU8zGWNdgGKtMI0yMOFrVK8OC\" in parents and trashed = false'\n",
            "2019-05-04 19:28:18,866 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221Mgv419noU8zGWNdgGKtMI0yMOFrVK8OC%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:19,048 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/19EooAw0DlJRM-uPMJU4aNT5OJTrxr1Ju?alt=media\n",
            "2019-05-04 19:28:19,388 861 140249963870080: Loading metrics_0024.npy from 1Mgv419noU8zGWNdgGKtMI0yMOFrVK8OC\n",
            "2019-05-04 19:28:19,394 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1Gy89rsZsmVcE_LU3xXtyOaApKmq_6Ehn\" in parents and trashed = false'\n",
            "2019-05-04 19:28:19,397 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221Gy89rsZsmVcE_LU3xXtyOaApKmq_6Ehn%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:19,665 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/1ENu_5-i1emUbCXOIGXobkblXC0LQkRA7?alt=media\n",
            "2019-05-04 19:28:19,925 861 140249963870080: Loading metrics_0024.npy from 1Gy89rsZsmVcE_LU3xXtyOaApKmq_6Ehn\n",
            "2019-05-04 19:28:19,930 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1QZzaJWmclcaHzPABJFZW9m3FyL1OdrUu\" in parents and trashed = false'\n",
            "2019-05-04 19:28:19,938 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221QZzaJWmclcaHzPABJFZW9m3FyL1OdrUu%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:20,147 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/1WuJZ18YXPNIB5fg2ErirhBa5iMiwwtnb?alt=media\n",
            "2019-05-04 19:28:20,607 861 140249963870080: Loading metrics_0024.npy from 1QZzaJWmclcaHzPABJFZW9m3FyL1OdrUu\n",
            "2019-05-04 19:28:20,612 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"10aXr5M5qD6p9mno6ngMseJ4_mxAzwcIl\" in parents and trashed = false'\n",
            "2019-05-04 19:28:20,620 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%2210aXr5M5qD6p9mno6ngMseJ4_mxAzwcIl%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:20,809 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/1EwHOKnYeW8ypsbRaFl06zcFlbUwMTYWL?alt=media\n",
            "2019-05-04 19:28:21,110 861 140249963870080: Loading metrics_0024.npy from 10aXr5M5qD6p9mno6ngMseJ4_mxAzwcIl\n",
            "2019-05-04 19:28:21,117 861 140249963870080: Loading from z00500\n",
            "2019-05-04 19:28:21,121 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=%221Yfqug54MznnEIMRTBTxZBf5eD6TrXNSB%22+in+parents&alt=json\n",
            "2019-05-04 19:28:21,367 861 140249963870080: Found 6 seeds\n",
            "2019-05-04 19:28:21,368 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1ie4SeioXKTQrN-hzPyXHBlz1RW6VjmWe\" in parents and trashed = false'\n",
            "2019-05-04 19:28:21,376 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221ie4SeioXKTQrN-hzPyXHBlz1RW6VjmWe%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:21,581 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1S9KXRMW7eQZLeI4_HsOzJuGZdKutdsjc\" in parents and trashed = false'\n",
            "2019-05-04 19:28:21,584 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221S9KXRMW7eQZLeI4_HsOzJuGZdKutdsjc%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:21,772 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"14NGhadfnUFaAbKl176spr4N2o5kJIlWP\" in parents and trashed = false'\n",
            "2019-05-04 19:28:21,775 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%2214NGhadfnUFaAbKl176spr4N2o5kJIlWP%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:21,949 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1Z27KEDG2njG_BQLj-sFuDOyzpepstxDG\" in parents and trashed = false'\n",
            "2019-05-04 19:28:21,952 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221Z27KEDG2njG_BQLj-sFuDOyzpepstxDG%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:22,156 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1vZyHBMfHLMaPSRMNQRsWIrB5vob_ZHTP\" in parents and trashed = false'\n",
            "2019-05-04 19:28:22,160 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221vZyHBMfHLMaPSRMNQRsWIrB5vob_ZHTP%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:22,341 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1o8x6IzVvE3aP8BhL0aHCb0dYIH9VGawq\" in parents and trashed = false'\n",
            "2019-05-04 19:28:22,347 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221o8x6IzVvE3aP8BhL0aHCb0dYIH9VGawq%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:22,524 861 140249963870080: Loading from z00100\n",
            "2019-05-04 19:28:22,529 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=%221dGq4sUS_fkpGlp6W1LxrT7k_fFPTtZj8%22+in+parents&alt=json\n",
            "2019-05-04 19:28:22,702 861 140249963870080: Found 5 seeds\n",
            "2019-05-04 19:28:22,703 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1TUtv0mwOh-CIDEwjBxpCr0hhTgTdmwHk\" in parents and trashed = false'\n",
            "2019-05-04 19:28:22,707 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221TUtv0mwOh-CIDEwjBxpCr0hhTgTdmwHk%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:22,894 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/1jtMQzKtyN2OQzuNxhWKGHX-dvtmnN9hp?alt=media\n",
            "2019-05-04 19:28:23,145 861 140249963870080: Loading metrics_0024.npy from 1TUtv0mwOh-CIDEwjBxpCr0hhTgTdmwHk\n",
            "2019-05-04 19:28:23,149 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1KDRdEDsW_h3CFv2PbbsouKkXc89e6tTy\" in parents and trashed = false'\n",
            "2019-05-04 19:28:23,153 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221KDRdEDsW_h3CFv2PbbsouKkXc89e6tTy%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:23,388 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/1l4urLSHA9RlFpA91y-3otDzWQxTDc9w_?alt=media\n",
            "2019-05-04 19:28:23,724 861 140249963870080: Loading metrics_0024.npy from 1KDRdEDsW_h3CFv2PbbsouKkXc89e6tTy\n",
            "2019-05-04 19:28:23,729 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"11k_jDwnWx1jPkC_dcabcPCQxNp0nnDib\" in parents and trashed = false'\n",
            "2019-05-04 19:28:23,733 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%2211k_jDwnWx1jPkC_dcabcPCQxNp0nnDib%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:23,936 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/1I5R0NRxWVUE2DfL_avaFvtBlpZtKy2OH?alt=media\n",
            "2019-05-04 19:28:24,181 861 140249963870080: Loading metrics_0024.npy from 11k_jDwnWx1jPkC_dcabcPCQxNp0nnDib\n",
            "2019-05-04 19:28:24,185 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1CGReU-EAVwWnITeBGPeZy7MFpa5FqHmW\" in parents and trashed = false'\n",
            "2019-05-04 19:28:24,189 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221CGReU-EAVwWnITeBGPeZy7MFpa5FqHmW%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:24,361 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/1crHTykJAHik0gFdpOUb5jkpKYAv9NBMK?alt=media\n",
            "2019-05-04 19:28:24,605 861 140249963870080: Loading metrics_0024.npy from 1CGReU-EAVwWnITeBGPeZy7MFpa5FqHmW\n",
            "2019-05-04 19:28:24,611 861 140249963870080: Submitting query 'name contains \"metrics_0024.npy\" and \"1axzhPe35bUlsACUDjn7y_OILkUuWWr4w\" in parents and trashed = false'\n",
            "2019-05-04 19:28:24,616 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22metrics_0024.npy%22+and+%221axzhPe35bUlsACUDjn7y_OILkUuWWr4w%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:24,791 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files/1fAgoXbz5yK0hjvlLZMUz2KV77n60o2Mm?alt=media\n",
            "2019-05-04 19:28:25,036 861 140249963870080: Loading metrics_0024.npy from 1axzhPe35bUlsACUDjn7y_OILkUuWWr4w\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipVcMFmLx93d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert all(metrics['z00005'].columns == loaded_metrics.index)\n",
        "\n",
        "list_of_seed_indices = [set(v.index) for k, v in metrics.items()]\n",
        "\n",
        "all_seeds = sorted(set.union(*list_of_seed_indices))\n",
        "idents = sorted([ident_tuple[0] for ident_tuple in idents_tuples])\n",
        "\n",
        "presence_pd = pd.DataFrame('x', index=all_seeds, columns=idents)\n",
        "\n",
        "# for k, v in metrics.items():\n",
        "#     r = np.in1d(all_seeds, v.index)\n",
        "#     c = np.in1d(idents, k)\n",
        "#     presence_pd.loc[r, c] = 'o'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-1QiwycSd5R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "outputId": "609d7b5e-3108-4aa5-f97d-08cca86047de"
      },
      "source": [
        "\n",
        "metrics_multiindex = pd.concat(metrics, axis=1)\n",
        "print(metrics_multiindex['z00500'])\n",
        "# print(metrics.keys\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        conv_wasserstein  conv_mmd  conv_acc  conv_acc_t  conv_acc_f  \\\n",
            "seed_a               NaN       NaN       NaN         NaN         NaN   \n",
            "seed_b               NaN       NaN       NaN         NaN         NaN   \n",
            "seed_c               NaN       NaN       NaN         NaN         NaN   \n",
            "seed_d               NaN       NaN       NaN         NaN         NaN   \n",
            "seed_e               NaN       NaN       NaN         NaN         NaN   \n",
            "seed_f               NaN       NaN       NaN         NaN         NaN   \n",
            "seed_g               NaN       NaN       NaN         NaN         NaN   \n",
            "seed_h               NaN       NaN       NaN         NaN         NaN   \n",
            "seed_i               NaN       NaN       NaN         NaN         NaN   \n",
            "seed_j               NaN       NaN       NaN         NaN         NaN   \n",
            "seed_k               NaN       NaN       NaN         NaN         NaN   \n",
            "seed_l               NaN       NaN       NaN         NaN         NaN   \n",
            "seed_m               NaN       NaN       NaN         NaN         NaN   \n",
            "\n",
            "        conv_precision  conv_recall  inception_score  mode_score  fid  \n",
            "seed_a             NaN          NaN              NaN         NaN  NaN  \n",
            "seed_b             NaN          NaN              NaN         NaN  NaN  \n",
            "seed_c             NaN          NaN              NaN         NaN  NaN  \n",
            "seed_d             NaN          NaN              NaN         NaN  NaN  \n",
            "seed_e             NaN          NaN              NaN         NaN  NaN  \n",
            "seed_f             NaN          NaN              NaN         NaN  NaN  \n",
            "seed_g             NaN          NaN              NaN         NaN  NaN  \n",
            "seed_h             NaN          NaN              NaN         NaN  NaN  \n",
            "seed_i             NaN          NaN              NaN         NaN  NaN  \n",
            "seed_j             NaN          NaN              NaN         NaN  NaN  \n",
            "seed_k             NaN          NaN              NaN         NaN  NaN  \n",
            "seed_l             NaN          NaN              NaN         NaN  NaN  \n",
            "seed_m             NaN          NaN              NaN         NaN  NaN  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
            "of pandas will change to not sort by default.\n",
            "\n",
            "To accept the future behavior, pass 'sort=False'.\n",
            "\n",
            "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
            "\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBaPWcaKTGWT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "09535f20-48b2-44a8-e513-1d7633fd4f1c"
      },
      "source": [
        "print(metrics['z00500'])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        conv_wasserstein  conv_mmd  conv_acc  conv_acc_t  conv_acc_f  \\\n",
            "seed_a               NaN       NaN       NaN         NaN         NaN   \n",
            "seed_b               NaN       NaN       NaN         NaN         NaN   \n",
            "seed_c               NaN       NaN       NaN         NaN         NaN   \n",
            "seed_d               NaN       NaN       NaN         NaN         NaN   \n",
            "seed_l               NaN       NaN       NaN         NaN         NaN   \n",
            "seed_m               NaN       NaN       NaN         NaN         NaN   \n",
            "\n",
            "        conv_precision  conv_recall  inception_score  mode_score  fid  \n",
            "seed_a             NaN          NaN              NaN         NaN  NaN  \n",
            "seed_b             NaN          NaN              NaN         NaN  NaN  \n",
            "seed_c             NaN          NaN              NaN         NaN  NaN  \n",
            "seed_d             NaN          NaN              NaN         NaN  NaN  \n",
            "seed_l             NaN          NaN              NaN         NaN  NaN  \n",
            "seed_m             NaN          NaN              NaN         NaN  NaN  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-3rtfb6t0cF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "lines = []\n",
        "# lines += [presence_pd.to_string()]\n",
        "lines += [presence_pd.to_html()]\n",
        "\n",
        "subject = \"Results completeness report\"\n",
        "message = \"\\n\".join(lines)\n",
        "attachments = []\n",
        "send_email.send_mail_from_robotmatoba(to_addrs,\n",
        "                                      subject,\n",
        "                                      message, \n",
        "                                      attachments)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUdI4bcScWlQ",
        "colab_type": "code",
        "outputId": "7eaa77a4-8040-48d6-890a-df2862457432",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# ident = ident_tuple[0]\n",
        "# ident_fid = ident_tuple[1]\n",
        "# logger.info(\"Loading from {}\".format(ident))\n",
        "\n",
        "# metrics_pattern.format(collate_epoch)\n",
        "\n",
        "# seed_tuples = gdrive.list_dir(ident_fid)\n",
        "# num_seeds = len(seed_tuples)\n",
        "# logger.info(\"Found {} seeds\".format(num_seeds))\n",
        "# for seed_tuple in seed_tuples:\n",
        "#     seed_identifier = seed_tuple[0]\n",
        "#     seed_fid = seed_tuple[1]\n",
        "#     # filename = \"{}_{}\".format(ident, seed_identifier)\n",
        "#     logger.info(\"Loading {}/{}\".format(ident, seed_identifier))\n",
        "#     filename = metrics_pattern.format(collate_epoch)\n",
        "#     _ = _download_file_locally(filename, seed_fid)\n",
        "lines\n",
        "# print(_)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>z00005</th>\\n      <th>z00010</th>\\n      <th>z00025</th>\\n      <th>z00100</th>\\n      <th>z00200</th>\\n      <th>z00500</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>seed_a</th>\\n      <td>o</td>\\n      <td>o</td>\\n      <td>o</td>\\n      <td>o</td>\\n      <td>x</td>\\n      <td>o</td>\\n    </tr>\\n    <tr>\\n      <th>seed_b</th>\\n      <td>o</td>\\n      <td>o</td>\\n      <td>o</td>\\n      <td>o</td>\\n      <td>x</td>\\n      <td>o</td>\\n    </tr>\\n    <tr>\\n      <th>seed_c</th>\\n      <td>o</td>\\n      <td>o</td>\\n      <td>o</td>\\n      <td>o</td>\\n      <td>x</td>\\n      <td>o</td>\\n    </tr>\\n    <tr>\\n      <th>seed_d</th>\\n      <td>o</td>\\n      <td>o</td>\\n      <td>o</td>\\n      <td>o</td>\\n      <td>x</td>\\n      <td>o</td>\\n    </tr>\\n    <tr>\\n      <th>seed_e</th>\\n      <td>o</td>\\n      <td>o</td>\\n      <td>o</td>\\n      <td>o</td>\\n      <td>x</td>\\n      <td>x</td>\\n    </tr>\\n    <tr>\\n      <th>seed_f</th>\\n      <td>o</td>\\n      <td>o</td>\\n      <td>o</td>\\n      <td>x</td>\\n      <td>x</td>\\n      <td>x</td>\\n    </tr>\\n    <tr>\\n      <th>seed_g</th>\\n      <td>o</td>\\n      <td>o</td>\\n      <td>o</td>\\n      <td>x</td>\\n      <td>x</td>\\n      <td>x</td>\\n    </tr>\\n    <tr>\\n      <th>seed_h</th>\\n      <td>o</td>\\n      <td>o</td>\\n      <td>o</td>\\n      <td>x</td>\\n      <td>x</td>\\n      <td>x</td>\\n    </tr>\\n    <tr>\\n      <th>seed_i</th>\\n      <td>o</td>\\n      <td>o</td>\\n      <td>o</td>\\n      <td>x</td>\\n      <td>x</td>\\n      <td>x</td>\\n    </tr>\\n    <tr>\\n      <th>seed_j</th>\\n      <td>o</td>\\n      <td>o</td>\\n      <td>o</td>\\n      <td>x</td>\\n      <td>x</td>\\n      <td>x</td>\\n    </tr>\\n    <tr>\\n      <th>seed_k</th>\\n      <td>o</td>\\n      <td>o</td>\\n      <td>o</td>\\n      <td>x</td>\\n      <td>x</td>\\n      <td>x</td>\\n    </tr>\\n    <tr>\\n      <th>seed_l</th>\\n      <td>o</td>\\n      <td>o</td>\\n      <td>x</td>\\n      <td>x</td>\\n      <td>o</td>\\n      <td>o</td>\\n    </tr>\\n    <tr>\\n      <th>seed_m</th>\\n      <td>o</td>\\n      <td>o</td>\\n      <td>x</td>\\n      <td>x</td>\\n      <td>x</td>\\n      <td>o</td>\\n    </tr>\\n  </tbody>\\n</table>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfxGoo1RxUrA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def _get_results_for_seed(dataset: str, \n",
        "                          seed_str: str):\n",
        "  pass\n",
        "\n",
        "\n",
        "# def _get_results_for_all_seeds(dataset: str):\n",
        "#     all_seed_strs = \n",
        "#     pass\n",
        "\n",
        "# seed_strs = \n",
        "seed_str = 'a'\n",
        "  \n",
        "idents = ['z00010', 'z00025', 'z00050', 'z00100', 'z00500']\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JKJKMiQz01p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net_g_pattern = 'netG_epoch'\n",
        "net_d_pattern = 'netD_epoch'\n",
        "\n",
        "checkpoint_pattern = '{}{:04d}.pth'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onmQ-Nd3bXFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_folder_r = os.path.join(out_folder_local, 'real/')\n",
        "save_folder_f = os.path.join(out_folder_local, 'fake/')\n",
        "\n",
        "os.makedirs(save_folder_r, exist_ok=True)\n",
        "os.makedirs(save_folder_f, exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTMbS2qhPE2R",
        "colab_type": "code",
        "outputId": "3399712a-2045-4dc0-c214-7980df45fbda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "net_g_items = gdrive.find_items(name=net_g_pattern, parent_fid=parent_fid, skip_trashed=True)\n",
        "net_d_items = gdrive.find_items(name=net_d_pattern, parent_fid=parent_fid, skip_trashed=True)\n",
        "sorted_net_g_filenames = sorted([x[0] for x in net_g_items])\n",
        "sorted_net_d_filenames = sorted([x[0] for x in net_d_items])\n",
        "# logger.info(sorted_net_g_filenames)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-05-04 19:28:26,162 861 140249963870080: Submitting query 'name contains \"netG_epoch\" and \"1mxzCSp8zzJaAO0m66V7V3vbg2BrAcRxJ\" in parents and trashed = false'\n",
            "2019-05-04 19:28:26,169 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22netG_epoch%22+and+%221mxzCSp8zzJaAO0m66V7V3vbg2BrAcRxJ%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:28:26,334 861 140249963870080: Submitting query 'name contains \"netD_epoch\" and \"1mxzCSp8zzJaAO0m66V7V3vbg2BrAcRxJ\" in parents and trashed = false'\n",
            "2019-05-04 19:28:26,338 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22netD_epoch%22+and+%221mxzCSp8zzJaAO0m66V7V3vbg2BrAcRxJ%22+in+parents+and+trashed+%3D+false&alt=json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaX2RRDasY0Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attempt_reload = True\n",
        "# attempt_reload = False\n",
        "# max_load = 0\n",
        "max_load = None\n",
        "\n",
        "\n",
        "if attempt_reload and len(sorted_net_g_filenames) > 2 and len(sorted_net_d_filenames) > 2:\n",
        "    latest_net_g_filename = max(sorted_net_g_filenames)\n",
        "    latest_net_d_filename = max(sorted_net_d_filenames)\n",
        "\n",
        "    latest_net_g_epoch = _get_epoch_from_checkpoint(latest_net_g_filename)\n",
        "    latest_net_d_epoch = _get_epoch_from_checkpoint(latest_net_d_filename)\n",
        "\n",
        "    latest_epoch = min(latest_net_g_epoch, latest_net_d_epoch)\n",
        "\n",
        "    net_g_filename = checkpoint_pattern.format(net_g_pattern, latest_epoch)\n",
        "    net_d_filename = checkpoint_pattern.format(net_d_pattern, latest_epoch)\n",
        "\n",
        "    last_net_g_fullfilename = sorted_net_g_filenames[sorted_net_g_filenames.index(net_g_filename) - 1]\n",
        "    last_net_d_fullfilename = sorted_net_d_filenames[sorted_net_d_filenames.index(net_d_filename) - 1]\n",
        "\n",
        "    g_epoch = _get_epoch_from_checkpoint(last_net_g_fullfilename)\n",
        "    d_epoch = _get_epoch_from_checkpoint(last_net_d_fullfilename)\n",
        "\n",
        "    load_epoch = min(d_epoch, g_epoch)\n",
        "    if max_load is not None:\n",
        "       load_epoch = min(load_epoch, max_load)\n",
        "        \n",
        "    net_g_fullfilename = checkpoint_pattern.format(net_g_pattern, load_epoch)\n",
        "    net_d_fullfilename = checkpoint_pattern.format(net_d_pattern, load_epoch)\n",
        "                \n",
        "    _download_file_locally(net_d_fullfilename, parent_fid)\n",
        "    _download_file_locally(net_g_fullfilename, parent_fid)\n",
        "    min_iter = load_epoch\n",
        "    logger.info(\"Loading from epoch {:04d}\".format(load_epoch))\n",
        "\n",
        "else:\n",
        "    net_g_fullfilename = ''\n",
        "    net_d_fullfilename = ''\n",
        "\n",
        "    min_iter = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrcWGX_othO9",
        "colab_type": "code",
        "outputId": "0df752a7-83ed-47a9-97ac-9a56484935da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 940
        }
      },
      "source": [
        "if net_g_fullfilename != '':\n",
        "    netG.load_state_dict(torch.load(net_g_fullfilename))\n",
        "\n",
        "if net_d_fullfilename != '':\n",
        "    netD.load_state_dict(torch.load(net_d_fullfilename))\n",
        "\n",
        "logger.info(netD)\n",
        "logger.info(netG)\n",
        "\n",
        "checkpoint_dir = out_folder_local\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    os.makedirs(out_folder_local, exist_ok=True)\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "    fixed_noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
        "    real_label = 1\n",
        "    fake_label = 0\n",
        "\n",
        "    dataloader = torch.utils.data.DataLoader(dataset,\n",
        "                                             batch_size=batch_size,\n",
        "                                             shuffle=True,\n",
        "                                             num_workers=num_workers)\n",
        "\n",
        "    optimizer_d = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "    optimizer_g = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "\n",
        "    dataloader_size = len(dataloader)\n",
        "    \n",
        "    logger.info(\"Running iterations {} to {}\".format(min_iter, max_iter))\n",
        "    \n",
        "    for epoch in range(min_iter, max_iter):\n",
        "        for i, data in enumerate(dataloader, 0):\n",
        "            # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "            # train with real\n",
        "            netD.zero_grad()\n",
        "            real_cpu = data[0].to(device)\n",
        "            batch_size = real_cpu.size(0)\n",
        "            label = torch.full((batch_size,), real_label, device=device)\n",
        "\n",
        "            output = netD(real_cpu)\n",
        "            errD_real = criterion(output, label)\n",
        "            errD_real.backward()\n",
        "            D_x = output.mean().item()\n",
        "\n",
        "            # train with fake\n",
        "            noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
        "            fake = netG(noise)\n",
        "            label.fill_(fake_label)\n",
        "            output = netD(fake.detach())\n",
        "            errD_fake = criterion(output, label)\n",
        "            errD_fake.backward()\n",
        "            D_G_z1 = output.mean().item()\n",
        "            errD = errD_real + errD_fake\n",
        "            optimizer_d.step()\n",
        "\n",
        "            # (2) Update G network: maximize log(D(G(z)))\n",
        "            netG.zero_grad()\n",
        "            label.fill_(real_label)  # fake labels are real for generator cost\n",
        "            output = netD(fake)\n",
        "            errG = criterion(output, label)\n",
        "            errG.backward()\n",
        "            D_G_z2 = output.mean().item()\n",
        "            optimizer_g.step()\n",
        "\n",
        "            if i % print_every_iteration == 0:\n",
        "                loss_d = errD.item()\n",
        "                loss_g = errG.item()\n",
        "\n",
        "                logger.info('[%d/%d] [%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
        "                      % (epoch, max_iter, i, dataloader_size, loss_d, loss_g, D_x, D_G_z1, D_G_z2))\n",
        "            if i % save_every_iteration == 0:\n",
        "                real_filename = '%s/real_samples.png' % out_folder_local\n",
        "                fake_filename = '%s/fake_samples_epoch_%03d.png' % (out_folder_local, epoch)\n",
        "\n",
        "                fake = netG(fixed_noise)\n",
        "                \n",
        "                vutils.save_image(real_cpu, real_filename, normalize=True)\n",
        "                vutils.save_image(fake.detach(), fake_filename, normalize=True)\n",
        "                \n",
        "        net_g_filename = checkpoint_pattern.format(net_g_pattern, epoch)\n",
        "        net_d_filename = checkpoint_pattern.format(net_d_pattern, epoch)\n",
        "\n",
        "        net_g_full_filename = os.path.join(checkpoint_dir, net_g_filename)\n",
        "        net_d_full_filename = os.path.join(checkpoint_dir, net_d_filename)\n",
        "\n",
        "        torch.save(netG.state_dict(), net_g_full_filename)\n",
        "        torch.save(netD.state_dict(), net_d_full_filename)\n",
        "\n",
        "        if 0 == epoch % checkpoint_every_epoch:\n",
        "            logger.info('Checkpointing epoch {}'.format(epoch))\n",
        "\n",
        "            # Delete any existing files with this name, to avoid ending up with multiple files\n",
        "            _delete_all_remote_files(net_g_filename, parent_fid=parent_fid)\n",
        "            _delete_all_remote_files(net_d_filename, parent_fid=parent_fid)\n",
        "            \n",
        "            gdrive.upload_file_to_folder(local_file=net_g_filename, parent_fid=parent_fid)\n",
        "            gdrive.upload_file_to_folder(local_file=net_d_filename, parent_fid=parent_fid) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-05-04 19:28:26,618 861 140249963870080: Discriminator(\n",
            "  (main): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
            "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace)\n",
            "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace)\n",
            "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace)\n",
            "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (12): Sigmoid()\n",
            "  )\n",
            ")\n",
            "2019-05-04 19:28:26,620 861 140249963870080: Generator(\n",
            "  (main): Sequential(\n",
            "    (0): ConvTranspose2d(200, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace)\n",
            "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace)\n",
            "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): ReLU(inplace)\n",
            "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (13): Tanh()\n",
            "  )\n",
            ")\n",
            "2019-05-04 19:28:26,623 861 140249963870080: Running iterations 0 to 25\n",
            "2019-05-04 19:28:27,183 861 140249963870080: [0/25] [0/782] Loss_D: 1.2768 Loss_G: 5.4980 D(x): 0.5247 D(G(z)): 0.3671 / 0.0050\n",
            "2019-05-04 19:28:41,612 861 140249963870080: [0/25] [200/782] Loss_D: 0.0037 Loss_G: 39.1927 D(x): 0.9965 D(G(z)): 0.0000 / 0.0000\n",
            "2019-05-04 19:28:56,352 861 140249963870080: [0/25] [400/782] Loss_D: 0.0002 Loss_G: 38.5677 D(x): 0.9998 D(G(z)): 0.0000 / 0.0000\n",
            "2019-05-04 19:29:11,438 861 140249963870080: [0/25] [600/782] Loss_D: 0.0001 Loss_G: 37.8909 D(x): 0.9999 D(G(z)): 0.0000 / 0.0000\n",
            "2019-05-04 19:29:25,350 861 140249963870080: Checkpointing epoch 0\n",
            "2019-05-04 19:29:25,352 861 140249963870080: Submitting query 'name contains \"netG_epoch0000.pth\" and \"1mxzCSp8zzJaAO0m66V7V3vbg2BrAcRxJ\" in parents and trashed = false'\n",
            "2019-05-04 19:29:25,362 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22netG_epoch0000.pth%22+and+%221mxzCSp8zzJaAO0m66V7V3vbg2BrAcRxJ%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:29:25,566 861 140249963870080: Submitting query 'name contains \"netD_epoch0000.pth\" and \"1mxzCSp8zzJaAO0m66V7V3vbg2BrAcRxJ\" in parents and trashed = false'\n",
            "2019-05-04 19:29:25,569 861 140249963870080: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22netD_epoch0000.pth%22+and+%221mxzCSp8zzJaAO0m66V7V3vbg2BrAcRxJ%22+in+parents+and+trashed+%3D+false&alt=json\n",
            "2019-05-04 19:29:25,785 861 140249963870080: URL being requested: POST https://www.googleapis.com/upload/drive/v3/files?fields=id&alt=json&uploadType=resumable\n",
            "2019-05-04 19:29:27,289 861 140249963870080: URL being requested: POST https://www.googleapis.com/upload/drive/v3/files?fields=id&alt=json&uploadType=resumable\n",
            "2019-05-04 19:29:28,829 861 140249963870080: [1/25] [0/782] Loss_D: 0.0001 Loss_G: 37.1655 D(x): 0.9999 D(G(z)): 0.0000 / 0.0000\n",
            "2019-05-04 19:29:43,494 861 140249963870080: [1/25] [200/782] Loss_D: 0.3360 Loss_G: 6.4834 D(x): 0.9335 D(G(z)): 0.1706 / 0.0066\n",
            "2019-05-04 19:29:58,160 861 140249963870080: [1/25] [400/782] Loss_D: 0.2547 Loss_G: 6.4799 D(x): 0.9190 D(G(z)): 0.1106 / 0.0022\n",
            "2019-05-04 19:30:12,881 861 140249963870080: [1/25] [600/782] Loss_D: 0.6967 Loss_G: 4.8749 D(x): 0.7880 D(G(z)): 0.1885 / 0.0577\n",
            "2019-05-04 19:30:26,478 861 140249963870080: [2/25] [0/782] Loss_D: 0.6919 Loss_G: 2.9233 D(x): 0.6731 D(G(z)): 0.0979 / 0.0784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW9WIm2JvMy1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "sample_size = 2000\n",
        "\n",
        "netG = Generator(ngpu).to(device)\n",
        "netG.apply(weights_init)\n",
        "\n",
        "# [emd-mmd-knn(knn,real,fake,precision,recall)]*4 - IS - mode_score - FID\n",
        "score_tr = np.zeros((max_iter, 4*7+3))\n",
        "# max_iter = 5\n",
        "for epoch in range(0, max_iter):\n",
        "    metrics_filename = metrics_pattern.format(epoch)z\n",
        "    logger.info(metrics_filename)\n",
        "    found_items = gdrive.find_items(name=metrics_filename, \n",
        "                                    parent_fid=parent_fid,\n",
        "                                    skip_trashed=True)\n",
        "    \n",
        "    if len(found_items) > 0:\n",
        "        assert len(found_items) <= 1\n",
        "        found_item = found_items[0]\n",
        "        assert found_item[0] == metrics_filename\n",
        "        _download_file_locally(metrics_filename, parent_fid)\n",
        "        s = np.load(metrics_filename)\n",
        "    else:\n",
        "        net_g_filename = checkpoint_pattern.format(net_g_pattern, epoch)\n",
        "\n",
        "        logger.info(\"Downloading {}\".format(net_g_filename))\n",
        "        try:\n",
        "            _download_file_locally(net_g_filename, parent_fid)\n",
        "            netG.load_state_dict(torch.load(net_g_filename))\n",
        "            logger.info(\"Computing metrics on {}\".format(net_g_filename))\n",
        "\n",
        "            s = metric.compute_score_raw(dataset_name, \n",
        "                                         image_size, \n",
        "                                         dataroot, \n",
        "                                         sample_size, \n",
        "                                         batch_size, \n",
        "                                         saveFolder_r=save_folder_r, \n",
        "                                         saveFolder_f=save_folder_f, \n",
        "                                         netG=netG, \n",
        "                                         nz=nz, \n",
        "                                         conv_model='inception_v3', \n",
        "                                         workers=num_workers)\n",
        "            np.save(metrics_filename, s)    \n",
        "            _delete_all_remote_files(metrics_filename, parent_fid=parent_fid)\n",
        "            gdrive.upload_file_to_folder(metrics_filename, parent_fid=parent_fid)\n",
        "        except: \n",
        "          s = np.nan\n",
        "    score_tr[epoch, :] = s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-q7ZeEnBW4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_rows = np.any(np.isfinite(score_tr), axis=1)\n",
        "plot_score_tr = score_tr[plot_rows, :]\n",
        "plot_axis = np.arange(len(plot_rows))[plot_rows] \n",
        "# print(plot_score_tr)\n",
        "# print(plot_axis)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6qF2276rw80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(net_g_full_filename)\n",
        "print(net_d_full_filename)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RilWbGeplNbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade git+https://github.com/Lyken17/pytorch-OpCounter.git\n",
        "\n",
        "#   # https://github.community/t5/How-to-use-Git-and-GitHub/Clone-private-repo/td-p/12616\n",
        "# !rm -rf matobapython\n",
        "# !git clone https://kylematoba:!!czsnd889.!!!!@github.com/kylematoba/matobapython.git\n",
        "    \n",
        "import thop\n",
        "\n",
        "flops_g, params_g = thop.profile(netG, input_size=(16, nz, 1, 1))\n",
        "flops_d, params_d = thop.profile(netD, input_size=(16, nc, 64, 64))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mNh6txYD8r-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "num_metrics = len(metric_names)\n",
        "\n",
        "metrics_np = np.full((num_metrics, ), np.nan)\n",
        "for idx in range(num_metrics):\n",
        "    metric_name = metric_names[idx]\n",
        "    metric_value = plot_score_tr[-1, idx]\n",
        "    metrics_np[idx] = metric_value\n",
        "\n",
        "metrics_pd = pd.Series(metrics_np, index=metric_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM-2QHVbkg9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attachments = []\n",
        "\n",
        "scale = .5\n",
        "for idx in range(num_metrics):  # idx = 0\n",
        "    metric_name = metric_names[idx]\n",
        "    logger.info(\"Plotting {}\".format(metric_name))\n",
        "    fig = plt.figure(figsize=(12 * scale, 4 * scale))\n",
        "    plt.plot(plot_axis, plot_score_tr[:, idx])\n",
        "    plt.title(metric_name)\n",
        "    ident = \"fig{:05d}\".format(idx)\n",
        "    fig_path = plotting.smart_save_fig(fig, ident=ident)\n",
        "    plt.close(fig)\n",
        "    attachments.append(fig_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7es7XvMwrPvj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2JCm-D8jD0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "storage_g_mb = os.path.getsize(net_g_full_filename) / 1e6\n",
        "storage_d_mb = os.path.getsize(net_d_full_filename) / 1e6\n",
        "\n",
        "lines = []\n",
        "lines += [\"Generator params, flops = {:.0f}, {:.0f}\".format(params_g, flops_g)]\n",
        "lines += [\"Discriminator params, flops = {:.0f}, {:.0f}\".format(flops_d, params_d)]\n",
        "lines += [\"Generator net storage (mb) = {:.0f}\".format(storage_g_mb)]\n",
        "lines += [\"Discriminator net storage (mb) = {:.0f}\".format(storage_d_mb)]\n",
        "lines += [\"Metrics after {} iterations ({}, seed = {})\".format(max_iter, identifier, prng_seed)]\n",
        "lines += [\"\\n\" + metrics_pd.to_string()]\n",
        "lines += [\"Real, then fake, images follow below\"]\n",
        "\n",
        "message = \"\\n\".join(lines)\n",
        "# logger.info(message)\n",
        "\n",
        "subject = 'GAN analysis results ({})'.format(identifier)\n",
        "\n",
        "attachments = [real_filename, fake_filename] + attachments\n",
        "\n",
        "send_email.send_mail_from_robotmatoba(to_addrs,\n",
        "                                      subject,\n",
        "                                      message, \n",
        "                                      attachments)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiiDugNNfjqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# filename = 'fake_samples_epoch_001.png'\n",
        "# filename = real_filename\n",
        "filename = fake_filename\n",
        "img = matplotlib.image.imread(filename)\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}